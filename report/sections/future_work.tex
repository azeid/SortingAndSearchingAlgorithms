In the effort of having more algorithms to evaluate and compare against the results reported in this paper, implementation of the Parallel Iterative Improvement algorithm can be revisited. Additionally, we believe that using a profiler to check for possible optimizations would also improve our results. The proposed course of action would be to implement this algorithm with CUDA, to make use of a GPUs numerous cores, in an effort to be as close as possible to the $n^2$ processors listed as the ideal resources for the algorithm. Current GPUs would enable realistic results to be obtained for $n$ ranging  up to multiple tens.
To go alone with that effort, finishing debugging and optimizing of the Master-Slave algorithm would be on the list as well (in addition to being the most attainable). This implementation could do with refining and debugging in order to run it against the other implementations. However, because of the bottleneck of the master I expect it to perform worse overall especially in the worst case-scenario.
Having more robust ways to measure effectiveness would help as well. While our benchmarking framework is effective and informative, there are always other things that can be looked. In addition, our implementations may be optimized and allow us to obtain even cleaner results.