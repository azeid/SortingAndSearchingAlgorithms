
\subsection{Methodology}

All of our implementations were written in Java. Initially we thought of measuring the performance of our implementations with a naive approach where we would measure the time either in milliseconds or nanoseconds for sorting the input array. We could for example simply use \texttt{System.currentTimeMillis()} or \texttt{System.nanoTime()}. However we quickly found out how unreliable the results would be, since we noticed really inconsistent results between runs. As Ponge\cite{architectBenchmarking} explains, this kind of benchmarking might be viable in programs written in statically compiled languages like C. However Java runs on a Virtual Machine and it uses \emph{Just-in-time} compilation, so the first time the code is run it is actually being interpreted and then is compiled to native code, depending on the actual platform that is running. Furthermore, the VM tries to use all kinds of different optimization like loop unrolling, inlining functions or on-stack replacements, making it difficult to get consistent results. \\
We decided to use Java Microbenchmark Harness (JMH)\footnote{http://openjdk.java.net/projects/code-tools/jmh/} for measuring the performance of our implementations. JMH is an open source benchmarking tool part of the OpenJDK. Although it does not entirely prevent all common pitfalls and inconsistencies introduced by the JVM, it does help mitigating them. \\
Next step was to use the generated test cases files as inputs for our benchmarks. There are different modes to run benchmarks in JMH. We decided to measure the average time of an operation in microseconds, where an operation is sorting the array for any given algorithm and input array. In this mode, JMH considers an iteration to be a slice of time running as many operations as possible, it measures the time for each operation and averages it. In order to avoid some of the JIT inconsistencies and other JVM  optimizations, JMH runs a few warm-up iterations. After that it runs, by default, 5 iterations where the results are actually recorded. For our measuring purposes we decided to run 3  five seconds warm-up iterations and 5 ten seconds actual iterations.\\

The overall benchmark running time was over 36 hours. This was because we had large data sizes and due to the bad performance of some sorting algorithms in their worst case such as Bubble sort. We had to exclude Insertion and Bubble sort when running the test cases with a data size of 10,000,000.

\subsection{Results}

TODO

We ran the benchmark suite in machine with an 4-cores and 8 logical processors @ 3.4Ghz and 24Gb of DDR4 RAM @ 3,401Mhz. The benchmark result report can be found at \url{https://github.com/azeid/SortingAndSearchingAlgorithms/tree/master/results}.\\

As a baseline we decided to run all the tests in our serial implementation of Gale-Shapley. Results are shows in Table \ref{tab:serial-gale-shapley}. In every cell the amount of milliseconds to complete an operation of the algorithm, i.e. get a result, and the margin of error is specified and a confidence interval of 99\%. 

\begin{table}[!ht]
    \centering
\begin{tabular}{|l|l|l|l|}
\hline
\multicolumn{1}{|c|}{\textbf{n}} & \multicolumn{1}{c|}{\textbf{Best (ms/op)}} & \multicolumn{1}{c|}{\textbf{Random (ms/op)}} & \multicolumn{1}{c|}{\textbf{Worst (ms/op)}} \\ \hline
10                               & 0.011 ±,0.001                              & 0.014 ±,0.001                                & 0.022 ±,0.001                               \\ \hline
100                              & 0.867 ±,0.009                              & 1.198 ±,0.003                                & 6.595 ±,0.227                               \\ \hline
200                              & 3.463 ±,0.064                              & 5.423 ±,0.238                                & 43.587 ±,0.563                              \\ \hline
1000                             & 87.740 ±,0.628                             & 139.563 ±,3.146                              & 8782.987 ± 3636.943                         \\ \hline
\end{tabular}
    \caption{Serial Gale-Shapley}
    \label{tab:serial-gale-shapley}
\end{table}

We then followed by running our parallel version of Gale-Shapley. Results are shown in Table \ref{tab:parallel-gale-shapley}.


\begin{table}[!ht]
    \centering
\begin{tabular}{|l|l|l|l|}
\hline
\multicolumn{1}{|c|}{\textbf{n}} & \multicolumn{1}{c|}{\textbf{Best (ms/op)}} & \multicolumn{1}{c|}{\textbf{Random (ms/op)}} & \multicolumn{1}{c|}{\textbf{Worst (ms/op)}} \\ \hline
10                               & 0.176 ±,0.011                              & 0.177 ±,0.004                                & 0.176 ±,0.010                               \\ \hline
100                              & 0.379 ±,0.013                              & 0.376 ±,0.011                                & 1.082 ±,0.009                               \\ \hline
200                              & 0.564 ±,0.022                              & 0.728 ±,0.059                                & 5.576 ±,0.106                               \\ \hline
1000                             & 2.115 ±,0.023                              & 3.751 ±,0.168                                & 482.950 ±,31.277                            \\ \hline
\end{tabular}
    \caption{Parallel Gale-Shapley}
    \label{tab:parallel-gale-shapley}
\end{table}

Finally we ran our approach to divide and conquer in parallel. Results are shown in Table \ref{tab:parallel-tseng-lee}

\begin{table}[!ht]
    \centering
\begin{tabular}{|l|l|l|l|}
\hline
\multicolumn{1}{|c|}{\textbf{n}} & \multicolumn{1}{c|}{\textbf{Best (ms/op)}} & \multicolumn{1}{c|}{\textbf{Random (ms/op)}} & \multicolumn{1}{c|}{\textbf{Worst (ms/op)}} \\ \hline
10                               & 0.168 ±,0.003                              & 0.169 ±,0.007                                & 0.174 ±,0.013                               \\ \hline
100                              & 0.691 ±,0.007                              & 1.008 ±,0.035                                & 1.999 ±,0.025                               \\ \hline
200                              & 2.153 ±,0.034                              & 3.773 ±,0.150                                & 8.559 ±,0.304                               \\ \hline
1000                             & 43.971 ±,0.752                             & 74.536 ±,2.207                               & 401.745 ±,7.819                             \\ \hline
\end{tabular}
    \caption{Parallel Tseng-Lee}
    \label{tab:parallel-tseng-lee}
\end{table}