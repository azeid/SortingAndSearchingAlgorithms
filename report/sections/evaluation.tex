
\subsection{Methodology}

All of our implementations were written in Java. Initially we thought of measuring the performance of our implementations with a naive approach where we would measure the time either in milliseconds or nanoseconds of solving the stable marriage problem. We could for example simply use \texttt{System.currentTimeMillis()} or \texttt{System.nanoTime()}. However we quickly found out how unreliable the results would be, since we noticed really inconsistent results between runs. As Ponge\cite{architectBenchmarking} explains, this kind of benchmarking might be viable in programs written in statically compiled languages like C. However Java runs on a Virtual Machine and it uses \emph{Just-in-time} compilation, so the first time the code is run it is actually being interpreted and then is compiled to native code, depending on the actual platform that is running. Furthermore, the VM tries to use all kinds of different optimization like loop unrolling, inlining functions or on-stack replacements, making it difficult to get consistent results. \\
We decided to use Java Microbenchmark Harness (JMH)\footnote{http://openjdk.java.net/projects/code-tools/jmh/} for measuring the performance of our implementations. JMH is an open source benchmarking tool part of the OpenJDK. Although it does not entirely prevent all common pitfalls and inconsistencies introduced by the JVM, it does help mitigating them. \\
Next step was to generate some test inputs for our benchmarks. We considered three different scenarios. Best case, where every man $m_i$ and every woman $w_i$ are each other first option. Random case, where the list of preferences for both genders are randomly shuffled. For the worst case we considered McVitie-Wilson\cite{mcvitie1971stable} worst case, Figure \ref{fig:worst_case} shows an example of the rankings for 5 men and women.

\begin{figure}
    \centering
    
    \begin{tabular}{lllllllllllll}
$M_1$ & 1     & 4    & 3    & 2    & 5    &  & $W_1$ & 4     & 3     & 2     & 1    & 5    \\
$M_2$ & 2     & 1    & 4    & 3    & 5    &  & $W_2$ & 1     & 5     & 4     & 3    & 2    \\
$M_3$ & 3     & 2    & 1    & 4    & 5    &  & $W_3$ & 2     & 1     & 5     & 4    & 3    \\
$M_4$ & 4     & 3    & 2    & 1    & 5    &  & $W_4$ & 3     & 2     & 1     & 5    & 4    \\
$M_5$ & 1     & 4    & 3    & 2    & 5    &  & $W_5$ & 5     & 4     & 3     & 2    & 1    \\
   & \multicolumn{5}{l}{Men's ranking} &  &    & \multicolumn{5}{l}{Women's Ranking}
\end{tabular}
    
    \caption{Worst case of stable marriage problem using McVitie-Wilson algorithm when $n=5$}
    \label{fig:worst_case}
\end{figure}

For each case we generated preferences matrices of size $n = {10, 100, 200, 1000}$. There are different modes to run benchmarks in JMH. We decided to measure the average time of an operation in milliseconds, where an operation is solving the stable marriage problem. In this mode, JMH considers an iteration to be a slice of time running as many operations as possible, it measures the time for each operation and averages it. In order to avoid some of the JIT inconsistencies and other JVM  optimizations, JMH runs a few warm-up iterations. After that it runs, by default, 5 iterations where the results are actually recorded. For our measuring purposes we decided to run 3  five seconds warm-up iterations and 5 ten seconds actual iterations.

\subsection{Results}

We ran the benchmark suite in machine with an AMD Ryzen 1700 8-core 16-threads @ 3.6Ghz and 16Gb of DDR4 RAM @ 3,200Mhz. As a baseline we decided to run all the tests in our serial implementation of Gale-Shapley. Results are shows in Table \ref{tab:serial-gale-shapley}. In every cell the amount of milliseconds to complete an operation of the algorithm, i.e. get a result, and the margin of error is specified and a confidence interval of 99\%. 

\begin{table}[h]
    \centering
\begin{tabular}{|l|l|l|l|}
\hline
\multicolumn{1}{|c|}{\textbf{n}} & \multicolumn{1}{c|}{\textbf{Best (ms/op)}} & \multicolumn{1}{c|}{\textbf{Random (ms/op)}} & \multicolumn{1}{c|}{\textbf{Worst (ms/op)}} \\ \hline
10                               & 0.011 ±,0.001                              & 0.014 ±,0.001                                & 0.022 ±,0.001                               \\ \hline
100                              & 0.867 ±,0.009                              & 1.198 ±,0.003                                & 6.595 ±,0.227                               \\ \hline
200                              & 3.463 ±,0.064                              & 5.423 ±,0.238                                & 43.587 ±,0.563                              \\ \hline
1000                             & 87.740 ±,0.628                             & 139.563 ±,3.146                              & 8782.987 ± 3636.943                         \\ \hline
\end{tabular}
    \caption{Serial Gale-Shapley}
    \label{tab:serial-gale-shapley}
\end{table}

We then followed by running our parallel version of Gale-Shapley. Results are shown in Table \ref{tab:parallel-gale-shapley}.


\begin{table}[h]
    \centering
\begin{tabular}{|l|l|l|l|}
\hline
\multicolumn{1}{|c|}{\textbf{n}} & \multicolumn{1}{c|}{\textbf{Best (ms/op)}} & \multicolumn{1}{c|}{\textbf{Random (ms/op)}} & \multicolumn{1}{c|}{\textbf{Worst (ms/op)}} \\ \hline
10                               & 0.176 ±,0.011                              & 0.177 ±,0.004                                & 0.176 ±,0.010                               \\ \hline
100                              & 0.379 ±,0.013                              & 0.376 ±,0.011                                & 1.082 ±,0.009                               \\ \hline
200                              & 0.564 ±,0.022                              & 0.728 ±,0.059                                & 5.576 ±,0.106                               \\ \hline
1000                             & 2.115 ±,0.023                              & 3.751 ±,0.168                                & 482.950 ±,31.277                            \\ \hline
\end{tabular}
    \caption{Parallel Gale-Shapley}
    \label{tab:parallel-gale-shapley}
\end{table}

Finally we ran our approach to divide and conquer in parallel. Results are shown in Table \ref{tab:parallel-tseng-lee}

\begin{table}[h]
    \centering
\begin{tabular}{|l|l|l|l|}
\hline
\multicolumn{1}{|c|}{\textbf{n}} & \multicolumn{1}{c|}{\textbf{Best (ms/op)}} & \multicolumn{1}{c|}{\textbf{Random (ms/op)}} & \multicolumn{1}{c|}{\textbf{Worst (ms/op)}} \\ \hline
10                               & 0.168 ±,0.003                              & 0.169 ±,0.007                                & 0.174 ±,0.013                               \\ \hline
100                              & 0.691 ±,0.007                              & 1.008 ±,0.035                                & 1.999 ±,0.025                               \\ \hline
200                              & 2.153 ±,0.034                              & 3.773 ±,0.150                                & 8.559 ±,0.304                               \\ \hline
1000                             & 43.971 ±,0.752                             & 74.536 ±,2.207                               & 401.745 ±,7.819                             \\ \hline
\end{tabular}
    \caption{Parallel Tseng-Lee}
    \label{tab:parallel-tseng-lee}
\end{table}

There a few things important to notice in these results. First, observe how the serial version is much faster than both parallel implementations for a small $n$, such as $n=10$. This is due to the overhead introduced of running multiple threads. One can observe also that the payoff of a parallel approach starts to have a significant payoff when $n \geq 100$. Another outstanding result is how fast is our implementation of parallel Gale-Shapley compared to parallel divide and conquer and of course the serial version, for the best and random case. However for the worst case both parallel algorithms seem to have a similar performance.